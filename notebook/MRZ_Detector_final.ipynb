{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MRZ_Detector_final","provenance":[],"collapsed_sections":["08iFN21AJtSN","BVAwcxOrJGqR"],"authorship_tag":"ABX9TyOsJTqCCvetuS5TUfL6kFB6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Aq3kM5IvKY-9"},"source":["## Init"]},{"cell_type":"code","metadata":{"id":"DPiWchwSHnKj"},"source":["!pip install albumentations==0.4.6\r\n","!pip install mrz\r\n","!pip install imantics"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5T-LGDQLJSfq"},"source":["# MRZ gen."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_vlBDpOHxkI","executionInfo":{"status":"ok","timestamp":1613655031560,"user_tz":-60,"elapsed":3838,"user":{"displayName":"Lucian Tin Udovičić","photoUrl":"","userId":"09646396854523139795"}},"outputId":"09e82b73-7bb5-4a0f-cfd7-d3f81c15b8cf"},"source":["!git clone https://github.com/luciantin/MRZ_Generator"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Cloning into 'MRZ_Generator'...\n","remote: Enumerating objects: 465, done.\u001b[K\n","remote: Counting objects: 100% (465/465), done.\u001b[K\n","remote: Compressing objects: 100% (441/441), done.\u001b[K\n","remote: Total 465 (delta 27), reused 447 (delta 16), pack-reused 0\u001b[K\n","Receiving objects: 100% (465/465), 25.92 MiB | 38.86 MiB/s, done.\n","Resolving deltas: 100% (27/27), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SRJ6ZAcqHyHE"},"source":["U settings.json postaviti sample size za train set, generirati slike, spremiti dir pod nazivom train_images i train_masks.\r\n","\r\n","Ponoviti to za val set, val_images i val_masks.\r\n","\r\n","Pokrenuti iz njegovog DIR-a zbog path-a"]},{"cell_type":"code","metadata":{"id":"PnlgHzwaIIOv"},"source":["!cd MRZ_Generator/ && mkdir result \r\n","!cd MRZ_Generator/result && mkdir images && mkdir masks && touch MRZ_values.json\r\n","!cd MRZ_Generator/ && python ./main.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8vnHkH0IVfy"},"source":["## Test slika\r\n","\r\n","import cv2\r\n","import matplotlib.pyplot as plt\r\n","\r\n","img = cv2.imread('MRZ_Generator/result/masks/100.bmp', cv2.IMREAD_GRAYSCALE)\r\n","print(img)\r\n","\r\n","plt.imshow(img, cmap='gray')\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCL1SfdNIbsL"},"source":["!git clone https://github.com/luciantin/MRZ-Detector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3H4BdkrX-Ib"},"source":["!cd MRZ-Detector/ && mkdir data && mkdir saved_images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"skcfwBSzYbGX"},"source":["!mv MRZ_Generator/result/images MRZ-Detector/data/train_images\r\n","!mv MRZ_Generator/result/images MRZ-Detector/data/train_masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lMNGtVUbYKOD"},"source":["!mv MRZ_Generator/result/images MRZ-Detector/data/val_images\r\n","!mv MRZ_Generator/result/images MRZ-Detector/data/val_masks"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yczjnk_GJeKt"},"source":["# MRZ detector"]},{"cell_type":"code","metadata":{"id":"72o_OiwSKBMx","executionInfo":{"status":"ok","timestamp":1613653114138,"user_tz":-60,"elapsed":1533,"user":{"displayName":"Lucian Tin Udovičić","photoUrl":"","userId":"09646396854523139795"}}},"source":["import torch\r\n","import torchvision\r\n","from torch.utils.data import Dataset\r\n","from torch.utils.data import DataLoader\r\n","from PIL import Image\r\n","import numpy as np\r\n","import os"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gGhS6j0xJB-0"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"D2tEB0ONIhBm"},"source":["\r\n","\r\n","\r\n","class MRZ_Dataset(Dataset):\r\n","    def __init__(self, image_dir, mask_dir, transform=None):\r\n","        self.image_dir = image_dir\r\n","        self.mask_dir = mask_dir\r\n","        self.transform = transform\r\n","        self.images = os.listdir(image_dir)\r\n","\r\n","    def __len__(self):\r\n","        return len(self.images)\r\n","\r\n","    def __getitem__(self, index):\r\n","        img_path = os.path.join(self.image_dir, self.images[index])\r\n","        mask_path = os.path.join(self.mask_dir, self.images[index].replace(\".png\", \".bmp\"))  ######\r\n","        # print(mask_path)\r\n","        image = np.array(Image.open(img_path).convert(\"RGB\"))\r\n","        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\r\n","        mask[mask == 255.0] = 1\r\n","\r\n","        if self.transform is not None:\r\n","            augmentations = self.transform(image=image, mask=mask)\r\n","            image = augmentations[\"image\"]\r\n","            mask = augmentations[\"mask\"]\r\n","\r\n","        return image, mask"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6J31C2IMJmTR"},"source":["## DataLoader"]},{"cell_type":"code","metadata":{"id":"WbJNiEXSIutG"},"source":["\r\n","def get_loaders(\r\n","    train_dir,\r\n","    train_maskdir,\r\n","    val_dir,\r\n","    val_maskdir,\r\n","    batch_size,\r\n","    train_transform,\r\n","    val_transform,\r\n","    num_workers=4,\r\n","    pin_memory=True,\r\n","):\r\n","    train_ds = MRZ_Dataset(\r\n","        image_dir=train_dir,\r\n","        mask_dir=train_maskdir,\r\n","        transform=train_transform,\r\n","    )\r\n","\r\n","    train_loader = DataLoader(\r\n","        train_ds,\r\n","        batch_size=batch_size,\r\n","        num_workers=num_workers,\r\n","        pin_memory=pin_memory,\r\n","        shuffle=True,\r\n","    )\r\n","\r\n","    val_ds = MRZ_Dataset(\r\n","        image_dir=val_dir,\r\n","        mask_dir=val_maskdir,\r\n","        transform=val_transform,\r\n","    )\r\n","\r\n","    val_loader = DataLoader(\r\n","        val_ds,\r\n","        batch_size=batch_size,\r\n","        num_workers=num_workers,\r\n","        pin_memory=pin_memory,\r\n","        shuffle=False,\r\n","    )\r\n","\r\n","    return train_loader, val_loader\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"08iFN21AJtSN"},"source":["## Dice Score\r\n","\r\n","[Sørensen-Dice similarity coefficient for image segmentation](https://www.mathworks.com/help/images/ref/dice.html)\r\n","\r\n","- tek nakon sto se izvrti epoha, ne sudjeluje u f.c."]},{"cell_type":"code","metadata":{"id":"3t-pt2_-JvtS"},"source":["def check_accuracy(loader, model, device=\"cuda\"):\r\n","    num_correct = 0\r\n","    num_pixels = 0\r\n","    dice_score = 0\r\n","    model.eval()\r\n","\r\n","    with torch.no_grad():\r\n","        for x, y in loader:\r\n","            x = x.to(device)\r\n","            y = y.to(device).unsqueeze(1)\r\n","            preds = torch.sigmoid(model(x))\r\n","            preds = (preds > 0.5).float()\r\n","            num_correct += (preds == y).sum()\r\n","            num_pixels += torch.numel(preds)\r\n","            dice_score += (2 * (preds * y).sum()) / (\r\n","                (preds + y).sum() + 1e-8\r\n","            )\r\n","\r\n","    print(\r\n","        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\r\n","    )\r\n","    print(f\"Dice score: {dice_score/len(loader)}\")\r\n","    model.train()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BVAwcxOrJGqR"},"source":["## Checkpoint"]},{"cell_type":"code","metadata":{"id":"jCi90_K_JLSC"},"source":["def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\r\n","    print(\"=> Saving checkpoint\")\r\n","    torch.save(state, filename)\r\n","\r\n","def load_checkpoint(checkpoint, model):\r\n","    print(\"=> Loading checkpoint\")\r\n","    model.load_state_dict(checkpoint[\"state_dict\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LW9u5myBKU8M"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"QF5zzUVvI2AW"},"source":["import torch\r\n","import torch.nn as nn\r\n","import torchvision.transforms.functional as TF\r\n","\r\n","import matplotlib.pyplot as plt\r\n","\r\n","TEST = False\r\n","\r\n","# dupla konvolucija za svaki korak u UNET-u\r\n","class DoubleConv(nn.Module):\r\n","    def __init__(self, in_channels, out_channels):  \r\n","        super(DoubleConv, self).__init__()\r\n","        self.conv = nn.Sequential(\r\n","            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False), # 1. konv\r\n","            nn.BatchNorm2d(out_channels), # normalizacija\r\n","            nn.ReLU(inplace=True),\r\n","            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\r\n","            nn.BatchNorm2d(out_channels),\r\n","            nn.ReLU(inplace=True),\r\n","        )\r\n","\r\n","    def forward(self, x):\r\n","        return self.conv(x)\r\n","\r\n","\r\n","# features je borj kanala (featura) u UNET-u za jednu stranu, druga strana ide u suprotnom smjeru po polju\r\n","# npr. za torch.Size([3, 256, 40, 40])\r\n","# 2d polje od 40x40 gdje svaki element ima polje od 256 elemenata, to su ti featuri? , svaki od tih elementata ima 3 elem. za RGB\r\n","# ulaznih kanala imamo 3 jer je rgb a izlaznih 1 jer imamo samo jednu kategoriju (2, ili je ili nije) \r\n","class UNET(nn.Module):\r\n","    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\r\n","        super(UNET, self).__init__()\r\n","        self.ups = nn.ModuleList()\r\n","        self.downs = nn.ModuleList()\r\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\r\n","\r\n","        #Down part\r\n","        for feature in features:\r\n","            self.downs.append(DoubleConv(in_channels, feature))\r\n","            in_channels = feature\r\n","\r\n","        #Up part\r\n","        for feature in reversed(features):\r\n","            self.ups.append(\r\n","                nn.ConvTranspose2d(\r\n","                    feature*2, feature, kernel_size=2, stride=2\r\n","                )\r\n","            )\r\n","            self.ups.append(DoubleConv(feature*2, feature))\r\n","\r\n","        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\r\n","        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\r\n","\r\n","\r\n","    def forward(self, x):\r\n","        skip_connections = []\r\n","\r\n","        for down in self.downs:\r\n","            x = down(x)\r\n","            skip_connections.append(x)\r\n","            x = self.pool(x)\r\n","\r\n","        x = self.bottleneck(x)\r\n","\r\n","        skip_connections = skip_connections[::-1]\r\n","\r\n","        for idx in range(0, len(self.ups), 2):\r\n","            x = self.ups[idx](x)\r\n","            skip_connection = skip_connections[idx//2]\r\n","\r\n","            if TEST == True:\r\n","              print(x[0][0].detach().numpy().shape)\r\n","              plt.imshow(x[0][1].detach().numpy(), cmap='gray')\r\n","              plt.show()\r\n","            \r\n","            if x.shape != skip_connection.shape:\r\n","                x = TF.resize(x, size=skip_connection.shape[2:])\r\n","\r\n","            concat_skip = torch.cat((skip_connection, x), dim=1)\r\n","            x = self.ups[idx+1](concat_skip)\r\n","\r\n","        return self.final_conv(x)\r\n","\r\n","def test():\r\n","    x = torch.randn((3, 1, 160, 160))\r\n","    model = UNET(in_channels=1, out_channels=1)\r\n","    preds = model(x)\r\n","    print(preds.shape)\r\n","    print(x.shape)\r\n","    assert x.shape == preds.shape\r\n","\r\n","# TEST = True\r\n","# test()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qNhI8VtjSai_"},"source":["## Parametri"]},{"cell_type":"code","metadata":{"id":"EArR49uESc-V"},"source":["LEARNING_RATE = 1e-4\r\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n","BATCH_SIZE = 10\r\n","NUM_EPOCHS = 3\r\n","NUM_WORKERS = 4\r\n","IMAGE_HEIGHT = 160*3 \r\n","IMAGE_WIDTH = 240*3  \r\n","PIN_MEMORY = True ## samo ako CUDA \r\n","LOAD_MODEL = False  \r\n","TRAIN_IMG_DIR = \"MRZ-Detector/data/train_images/\"\r\n","TRAIN_MASK_DIR = \"MRZ-Detector/data/train_masks/\"\r\n","VAL_IMG_DIR = \"MRZ-Detector/data/val_images/\"\r\n","VAL_MASK_DIR = \"MRZ-Detector/data/val_masks/\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S9kbhtP1S44k"},"source":["## Libs za train"]},{"cell_type":"code","metadata":{"id":"CWF6AAMQS5j8"},"source":["import torch\r\n","import albumentations as A\r\n","from albumentations.pytorch import ToTensorV2\r\n","from tqdm import tqdm\r\n","import torch.nn as nn\r\n","import torch.optim as optim\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AFPbrjaUU512"},"source":["## Transformacije"]},{"cell_type":"code","metadata":{"id":"pV9aiPxFU7le"},"source":["train_transform = A.Compose(\r\n","    [\r\n","        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\r\n","        # A.Rotate(limit=35, p=1.0),\r\n","        # A.HorizontalFlip(p=0.5),\r\n","        # A.VerticalFlip(p=0.1),\r\n","        A.Normalize(\r\n","            mean=[0.0, 0.0, 0.0],\r\n","            std=[1.0, 1.0, 1.0],\r\n","            max_pixel_value=255.0,\r\n","        ),\r\n","        ToTensorV2(),\r\n","    ],\r\n",")\r\n","\r\n","val_transforms = A.Compose(\r\n","    [\r\n","        A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\r\n","        A.Normalize(\r\n","            mean=[0.0, 0.0, 0.0],\r\n","            std=[1.0, 1.0, 1.0],\r\n","            max_pixel_value=255.0,\r\n","        ),\r\n","        ToTensorV2(),\r\n","    ],\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HPArqQqrS9O5"},"source":["## Train fn"]},{"cell_type":"code","metadata":{"id":"5fqKsj5RSwMA"},"source":["def train_fn(loader, model, optimizer, loss_fn, scaler):\r\n","    loop = tqdm(loader)\r\n","\r\n","    for batch_idx, (data, targets) in enumerate(loop):\r\n","        data = data.to(device=DEVICE)\r\n","        targets = targets.float().unsqueeze(1).to(device=DEVICE)\r\n","       \r\n","        # plt.imshow(np.transpose(targets[0].numpy(), (1, 2, 0)))\r\n","        # plt.show()\r\n","\r\n","        # forward\r\n","        with torch.cuda.amp.autocast():\r\n","            predictions = model(data)\r\n","            loss = loss_fn(predictions, targets)\r\n","        \r\n","        # plt.imshow(np.transpose(predictions[0].detach().numpy(), (1, 2, 0)))\r\n","        # plt.show()\r\n","\r\n","        # backward\r\n","        optimizer.zero_grad()\r\n","        scaler.scale(loss).backward()\r\n","        scaler.step(optimizer)\r\n","        scaler.update()\r\n","\r\n","        # update tqdm loop\r\n","        loop.set_postfix(loss=loss.item())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vE_vZtvnTm1_"},"source":["## Predict on Val dataset"]},{"cell_type":"code","metadata":{"id":"eGk7KzJAVRed"},"source":["def save_predictions_as_imgs(\r\n","    loader, model, folder=\"saved_images/\", device=\"cuda\"\r\n","):\r\n","    model.eval()\r\n","    for idx, (x, y) in enumerate(loader):\r\n","        x = x.to(device=device)\r\n","        with torch.no_grad():\r\n","            preds = torch.sigmoid(model(x))\r\n","            preds = (preds > 0.5).float()\r\n","        torchvision.utils.save_image(\r\n","            preds, f\"{folder}/pred_{idx}.png\"\r\n","        )\r\n","        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\r\n","\r\n","    model.train()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D829DzVwTpdP"},"source":["def predict():\r\n","    print('predictING')\r\n","    model = UNET(in_channels=3, out_channels=1).to(DEVICE)\r\n","    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\r\n","   \r\n","    train_loader, val_loader = get_loaders(\r\n","        TRAIN_IMG_DIR,\r\n","        TRAIN_MASK_DIR,\r\n","        VAL_IMG_DIR,\r\n","        VAL_MASK_DIR,\r\n","        BATCH_SIZE,\r\n","        train_transform,\r\n","        val_transforms,\r\n","        NUM_WORKERS,\r\n","        PIN_MEMORY,\r\n","    )\r\n","\r\n","    save_predictions_as_imgs(\r\n","        val_loader, model, folder=\"saved_images/\", device=DEVICE\r\n","    )\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cQove-86UDr8"},"source":["## Main Train Loop"]},{"cell_type":"code","metadata":{"id":"COyjF3IKI6SC"},"source":["def main():\r\n","    torch.cuda.empty_cache()\r\n","    \r\n","    model = UNET(in_channels=3, out_channels=1).to(DEVICE)\r\n","    loss_fn = nn.BCEWithLogitsLoss()\r\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\r\n","\r\n","    train_loader, val_loader = get_loaders(\r\n","        TRAIN_IMG_DIR,\r\n","        TRAIN_MASK_DIR,\r\n","        VAL_IMG_DIR,\r\n","        VAL_MASK_DIR,\r\n","        BATCH_SIZE,\r\n","        train_transform,\r\n","        val_transforms,\r\n","        NUM_WORKERS,\r\n","        PIN_MEMORY,\r\n","    )\r\n","\r\n","    if LOAD_MODEL:\r\n","        load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\r\n","\r\n","    check_accuracy(val_loader, model, device=DEVICE)\r\n","    scaler = torch.cuda.amp.GradScaler()\r\n","\r\n","    for epoch in range(NUM_EPOCHS):\r\n","        train_fn(train_loader, model, optimizer, loss_fn, scaler)\r\n","\r\n","        # save model\r\n","        checkpoint = {\r\n","            \"state_dict\": model.state_dict(),\r\n","            \"optimizer\": optimizer.state_dict(),\r\n","        }\r\n","        save_checkpoint(checkpoint)\r\n","\r\n","        # check accuracy\r\n","        check_accuracy(val_loader, model, device=DEVICE)\r\n","\r\n","        # print some examples to a folder\r\n","        save_predictions_as_imgs(\r\n","            val_loader, model, folder=\"MRZ-Detector/saved_images/\", device=DEVICE\r\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ys8YgkiQTcJs"},"source":["## Ispis DataLoadera"]},{"cell_type":"code","metadata":{"id":"QvuAgRhzTfEn"},"source":["def data_test():\r\n","    \r\n","    train_loader, val_loader = get_loaders(\r\n","        TRAIN_IMG_DIR,\r\n","        TRAIN_MASK_DIR,\r\n","        VAL_IMG_DIR,\r\n","        VAL_MASK_DIR,\r\n","        BATCH_SIZE,\r\n","        train_transform,\r\n","        val_transforms,\r\n","        NUM_WORKERS,\r\n","        PIN_MEMORY,\r\n","    )\r\n","    print(len(val_loader))\r\n","\r\n","    for idx, (x, y) in enumerate(val_loader):\r\n","        print(idx)\r\n","        # plt.imshow(np.transpose(y[0].numpy(), (1, 2, 0)))\r\n","        plt.imshow(y[0].numpy())\r\n","        plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SqrqNY3NTN3U"},"source":["## Single image prediction"]},{"cell_type":"code","metadata":{"id":"IVGIZNXyTQG8"},"source":["def predict_single():\r\n","  \r\n","  device=\"cuda\"\r\n","  \r\n","  image = np.array(Image.open('MRZ-Detector/data/val_images/0.png').convert(\"RGB\"))\r\n","  mask = np.array(Image.open('MRZ-Detector/data/val_masks/0.bmp').convert(\"L\"), dtype=np.float32)\r\n","  mask[mask == 255.0] = 1\r\n","  augmentations = val_transforms(image=image, mask=mask)\r\n","  image = augmentations[\"image\"]\r\n","  mask = augmentations[\"mask\"]\r\n","\r\n","  plt.imshow(image.squeeze().permute(1,2,0))\r\n","  plt.show()\r\n","  plt.imshow(mask, cmap='gray')\r\n","  plt.show()\r\n","  \r\n","  image = torch.tensor(image, requires_grad=True).to(DEVICE)\r\n","  image = image.unsqueeze(0)\r\n","\r\n","  model = UNET(in_channels=3, out_channels=1).to(DEVICE)\r\n","  load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\r\n","  # image = image.to(device=device)\r\n","  model.eval()\r\n","  with torch.no_grad():\r\n","    preds = torch.sigmoid(model(image))\r\n","    preds = (preds > 0.5).float()\r\n","  torchvision.utils.save_image(preds, \"./pred_100.png\")\r\n","  model.train()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZPNZpCfuTBpQ"},"source":["## TJT\r\n","\r\n","za predict i predict_single mora postojati checkpoint"]},{"cell_type":"code","metadata":{"id":"VbLGsh2uTDxo"},"source":["if __name__ == \"__main__\":\r\n","    # main()\r\n","    # predict_single()\r\n","    # predict()\r\n","    # data_test()"],"execution_count":null,"outputs":[]}]}